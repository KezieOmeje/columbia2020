{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework 2\n",
    "----------\n",
    "\n",
    "**1. Some review from the last class - Introduction to lists**\n",
    "\n",
    "It's one thing to store single values (a single number or a single string), but as we saw in class, we tend to collect a lot of data on different aspects of a person or a thing in the world. We saw that Python's built-in **dictionary** object is a good way to bundle different aspects of a thing into a single variable. Here are two examples - the first deals with a tweet from Donald Trump Jr. on the \"Learn to Code\" meme, and the second is an overall count of tweets on the meme for a given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Could someone explain to me why if I tell my kids to “learn to code” it’s likely sound parenting, but if I told a journalist the same it’s grounds for a <a href=\"https://twitter.com/Twitter?ref_src=twsrc%5Etfw\">@twitter</a> suspension?</p>&mdash; Donald Trump Jr. (@DonaldJTrumpJr) <a href=\"https://twitter.com/DonaldJTrumpJr/status/1089958848742518785?ref_src=twsrc%5Etfw\">January 28, 2019</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">Could someone explain to me why if I tell my kids to “learn to code” it’s likely sound parenting, but if I told a journalist the same it’s grounds for a <a href=\"https://twitter.com/Twitter?ref_src=twsrc%5Etfw\">@twitter</a> suspension?</p>&mdash; Donald Trump Jr. (@DonaldJTrumpJr) <a href=\"https://twitter.com/DonaldJTrumpJr/status/1089958848742518785?ref_src=twsrc%5Etfw\">January 28, 2019</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundling different aspects of a tweet\n",
    "tweet = {\"date\":\"Mon Jan 28 18:50:14 +0000 2019\",\n",
    "         \"text\":\"Could someone explain to me why if I tell my kids to 'learn to code' it’s likely sound parenting, but if I told a journalist the same it’s grounds for a @twitter suspension?\",\n",
    "         \"ID\":\"1089958848742518785\",\n",
    "         \"verified\":True,\n",
    "         \"source\":\"Twitter for iPhone\"}\n",
    "\n",
    "# Bundling date and activity around the \"Learn to Code\" meme on that date\n",
    "activity = {\"date\":\"January 20, 2019\", \"count\":474, \"day\":7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time we also saw examples of a **list**, another built-in data structure used to group information. As its name suggests, it is simply an **ordered collection** of objects. It has a well-defined first entry, a second entry and a last entry. It can hold different kinds of objects in each position. It is constructed using square brackets [ ] (as opposed to the curly braces for a dictionary).\n",
    "\n",
    "So to be clear, dictionaries store data with \"keys\" (or by name, if you will) as is done in a physical dictionary. Lists store data consecutively, so you access information in sequential order (extracting the first, third or hundredth element in the list). You will use these at different times. \n",
    "\n",
    "In class, our first example of a list involved counts of tweets containing \"learn to code\" or `#LearnToCode` or `#learn2code`. These were pulled from the Twitter Application Programming Interface (API). We will have a lot to say about API's and data access later in the term. \n",
    "\n",
    "In the list `counts` below, each element represents the number of tweets appearing on a single day, where the days range from January 20, 2019 to January 29, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [474,540,679,970,6279,8412,7448,9209,37595,20250]\n",
    "\n",
    "print(\"The type of 'counts' is\", type(counts), \"and its length is\", len(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we've been tricky with `print()`. We have several items to print in one line all separated by commas. Sssssslick! Also, a new \"global funciton\" called `len()`. This function returns the number of elements in a list, or its **length.** It is a global funciton because it can be called meaningfully on a lot of objects. For example, it will also tell you the length or number of characters in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\"learn to code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an object, a list carries both data as well as methods that you can apply. What kinds of things would you like to be able to do to this type of object? \n",
    "\n",
    "*Maybe add new objects to the list? `append()` does that.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the list of tweet counts\n",
    "\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now add something to the back of the list\n",
    "\n",
    "counts.append(2767)\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number 2767 is the count for the  30th (the data were pulled on the 30th, but only up until 10am, so the data are not complete. What else would we like to do with a list?\n",
    "\n",
    "*Maybe sort the list? `sort()` does that.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.sort()\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a container object (an object that holds or groups other objects), the most obvious set of operations you would like to perform should involve storing and retrieveing data from the list. This certainly was true for dictionaries. \n",
    "\n",
    "As we said, a list stores objects in a well-defined order. There is a first, a second, a third, and so on. You access these objects using **an index.**  A small catch: Python refers to positions starting at 0 and not at 1. So the first object has index 0, the second has index 1 and so on. Here's the full list and then let's pull out individual elements from the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first element\n",
    "counts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the third element\n",
    "counts[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sixth elemenet\n",
    "counts[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that the first, third and sixth element of the list above match what's in `counts`, printed above. Sometimes counting places from the back or righthand side of the list is easier. We use negative indices for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last element -- sneaky, right?\n",
    "counts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the fourth from the right\n",
    "counts[-4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can take out \"slices\" from a list by asking for not just a single index but a range. The construction `m:n` means starting from index `m` take all the data in a list up to, but not including, the index `n`. So `3:6` means data stored behind indices 3, 4 and 5 (or actual positions 4, 5 and 6 since we count from zero). A slice returns another list containing just the specified objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, you can pull more than one element with the : symbol to create a 'slice'\n",
    "print(\"From the fourth element to the end:\", counts[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Up to but not including the third element:\", counts[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"From the third up to but not including the sixth element:\", counts[2:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Knowing that `counts` runs from January 20, 2019 to January 29, 2019, create a list of strings, one giving each date from the 20th to the 29th. And then use a slice to extract the `counts` from the 23rd through the 27th.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [474,540,679,970,6279,8412,7448,9209,37595,20250]\n",
    "\n",
    "# put your code here to make the date list\n",
    "\n",
    "\n",
    "\n",
    "# put your code here to make the slice of the list counts corresponding to the dates from\n",
    "# January 23rd to the 27th.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Making lists**\n",
    "\n",
    "Certain operations produce lists. For example, we can divide a character string into pieces by \"splitting\" on a character using the method `split()`. This gives us a crude way to pull words from a string that represents a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = \"Could someone explain to me why if I tell my kids to 'learn to code' it's likely sound parenting, but if I told a journalist the same it's grounds for a @twitter suspension?\"\n",
    "\n",
    "# divide into substrings using the space character \" \" as a breakpoint — this gives a rough division into words.\n",
    "rough_words = line.split(\" \")\n",
    "rough_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are roughly\", len(rough_words), \"words in this tweet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use \"e\" as a breakpoint to split the string. Make sure you understand what happened here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line.split('e')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you understand lists. Create one and try out forming subsets, changing values and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Higher-level objects: A DataFrame**\n",
    "\n",
    "So we have seen lists and dictionaries, built-in structures that help us group data that are associated in some way. With dictionaries, we use names or keys to look up data. With lists, we use position to look things up. In many cases we actually need a mixture of both kinds of structures. The most common example is a table. \n",
    "\n",
    "Think about a spreadsheet. The basic structure involves rows and columns. In many cases the rows refer to different objects in the real world and the columns represent things we measure or record about each object. For example, if instead of one tweet from Donald Trump Jr., we had 100 or 1,000, we would have a series of rows the first entry could be the date and time he tweeted, the second could be the text of the tweet, the third could be the tweet's ID and so on. This happens so often that researchers have created a special object to emulate a spreadsheet. \n",
    "\n",
    "To see it in action, let's start with a count of the number of times the \"Learn to Code\" meme was referenced each day starting from 1/20 through 1/30 (again, with 1/30 we stopped recording at about 10am).\n",
    "\n",
    "We will store each day as a dictionary, with one key for the day and another for the overall tweet count on the meme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [\n",
    "    {\"day\":\"2019-01-30\",\"count\":2767},\n",
    "    {\"day\":\"2019-01-29\",\"count\":20250},\n",
    "    {\"day\":\"2019-01-28\",\"count\":37595},\n",
    "    {\"day\":\"2019-01-27\",\"count\":9209},\n",
    "    {\"day\":\"2019-01-26\",\"count\":7448},\n",
    "    {\"day\":\"2019-01-25\",\"count\":8412},\n",
    "    {\"day\":\"2019-01-24\",\"count\":6279},\n",
    "    {\"day\":\"2019-01-23\",\"count\":970},\n",
    "    {\"day\":\"2019-01-22\",\"count\":679},\n",
    "    {\"day\":\"2019-01-21\",\"count\":540},\n",
    "    {\"day\":\"2019-01-20\",\"count\":474}\n",
    "  ]\n",
    "\n",
    "type(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall `len()` gives you the number of elements in a list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Select data from the third element in the list (third element, not index) and then pull just the \"day\" from that third element. Then extract the \"count\" data from the fifth element.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here to extract the third element\n",
    "\n",
    "\n",
    "# Your code here to extract the \"day\" data from the third element\n",
    "\n",
    "\n",
    "# extract the count from the fifth row\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will, from time to time, make our data sets \"by hand\" like this, so it's worth seeing how it might be done. Our data format, the list of dictionaries, is trying really hard to create essentially a **table**. That is, a grid of data, where each row refers to a time period and then each column refers to either the date or the tweet count for the meme. For our simple data above, that would be a table with 11 rows and 2 columns.\n",
    "\n",
    "Interacting with even this simple data in this format is a little cumbersome. We can appeal to a higher-level object to create a proper table for us. You are probably familiar with Excel or some spreadsheet. These programs are all about tables. In Python, the answer to Excel (or a popular answer) is a so-called Pandas **DataFrame**. Pandas refers to a package contributed by a Python developer who wanted to make working with tabular data easier. \n",
    "\n",
    "[You can read more about Pandas here](http://pandas.pydata.org/)\n",
    "\n",
    "[And there are simple tutorials here](http://nbviewer.jupyter.org/github/jvns/pandas-cookbook/blob/v0.1/cookbook/Chapter%201%20-%20Reading%20from%20a%20CSV.ipynb)\n",
    "\n",
    "Pandas is a **package** that means its author has published data, functions and a host of new objects for the community to use. Whereas the built-in objects are basic and get us pretty far, often we need something special to make our lives easier. In the case of Pandas, an object of type DataFrame will help us manipulate (compute with, make graphs of, etc) simple tabular data. \n",
    "\n",
    "We can use the `times` object (the list of lists) and turn it into a DataFrame using the function `DataFrame().` (Yeah, that might be confusing — the type of the object is \"DataFrame\" and the name of the function to turn your data into an object of that type is also called \"DataFrame\". This is a fairly common naming convention, and functions like this are called \"constructors.\") As arguments, it takes the data itself (the list of dictionaries).\n",
    "\n",
    "We **import** the function \"DataFrame\" from the pandas package first. The import command is giving us super powers from the Pandas package to do things not built into the basic Python system. We will see this construction a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "tweet_times = DataFrame(times)\n",
    "tweet_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the way our data looks has changed. It's much more like an actual table now with column headings and the like. The DataFrame has lots of wonderful things you can do to it — lots of ways to compute with the data contained in the underlying table. \n",
    "\n",
    "One simple thing is just to get its size. How many rows and columns? This is an attribute, information, stored with the object that we can again access with \"dot\" notation. Because we are looking up information and not computing something (like making strings lowercase, say), we don't need parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_times.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside — Installing Packages.** Python has a set of built-in functionality and data types that it knows about. We have seen some really basic things so far — numbers and `print()`ing, say. The power of the platform is that people are constantly adding new functionality, making way for new kinds of data and new kinds of computation. This new capacity is organized into packages. Hence, `pandas`. \n",
    "\n",
    "Now some packages come with Python, some are added by Anaconda and still others you have to install yourself. You can search through the collection [here](https://pypi.org/). In particular, we are going to add plotting functionality to our notebook. It's basic so don't get overly excited yet. The package uses the service `plot.ly`. \n",
    "\n",
    "Below we use a \"UNIX shell command\" called `pip` to install the Python package `plotly` that provides us with access to its plotting facilities from within Python. You can read a bit about it [here](https://plot.ly/python/).\n",
    "\n",
    "**You do not need to do the next step if you did it in class. You only have to install a package once, unless it has been updated. A package is a bit like an app you might load on your phone - you can use it repeatedly until an improvement is made.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly==4.5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Making a plot**\n",
    "\n",
    "Now, we `import` a function that lets us make easy line plots. `plotly` has an `express` set of commands that make simple plots really quickly. Often when you are looking at data, you want to rifle through plots quickly. Our first example will be the command `line()` - with it, all we have to do is specify our x- and y-axes and maybe give the plot a title. You can read about the so-called plotly \"express\" [here](https://plot.ly/python/plotly-express/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.express import line\n",
    "\n",
    "fig = line(tweet_times, x=\"day\", y=\"count\", title='Learn to Code')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. More with DataFrames**\n",
    "\n",
    "Writing out data like we did to create the `tweets` data frame is really limiting. Instead, we can read data into a data frame from a variety of formats. The easiest is a [CSV](https://en.wikipedia.org/wiki/Comma-separated_values), which stands for \"comma separated values\". Each row of a CSV file corresponds to a different object (a person you survey, a tweet, a day on which we are counting tweets). In turn, a row consists of a set of values separated by commas - each row has the same number of values. So for a survey, we might ask each respondent 10 questions. Or for a group of tweets, we might collect the same 5 facts about each tweet. By convention, the first row in a CSV file gives the names of the values. \n",
    "\n",
    "As an example, we have pulled tweets from Twitter and binned the counts into 10-minute intervals and stored them in \n",
    "a [CSV file](https://github.com/computationaljournalism/columbia2020/raw/master/data/learn_counts.csv). Click on the link and have a look. For each row in the file, you will see two fields separated by a comma. The first row of the file is called a \"header\" and gives you the names of the variables recorded in each row. So you will see `time` and `count`. There are two entries in the header so each row has two entries.\n",
    "\n",
    "Each row after the first represents a ten minute period from the last few days, arranged so that the most recent are first and the oldest appear last in the file. Following the names in the header, the first entry in each row is the \"created at time\" and the second is a count of references to \"`learn to code`\" or `#LearnToCode` or `#Learn2Code`. Each row arranges the data about its time period according to the labels in the first row, and separates the entries by a comma. Hence CSV.\n",
    "\n",
    "In the cell below, we first import the function, `read_csv()`. Unlike `DataFrame()`, `read_csv()`  takes a CSV file and creates a DataFrame. Oh and it takes as its argument either the URL of a CSV or the location of a CSV file on your computer. Here we supply the URL on github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "# read in the tweets from the CSV file in our github data directory\n",
    "counts = read_csv(\"https://github.com/computationaljournalism/columbia2020/raw/master/data/learn_counts.csv\")\n",
    "\n",
    "type(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So We have 1,403 time periods (rows in the table) and 2 variables recorded for each. We can have a look at the \"top\" and \"bottom\" of the data set. These are printed with `head()` and `tail()`methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head()` and `tail()` methods of a DataFrame gives you five time periods from the start and end of the data (and you can give an argument to see more). It's important to look at the top and bottom of the file to check that everything looks consistent (column entries seem to mean what they should) and see how the data might be organized.\n",
    "\n",
    "We can now have a look at these values in a plot. Again, basic, but it motivates our investigations. Each point on the line is a time period. What should we be asking?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = line(counts, x=\"time\", y=\"count\", title='Learn to Code')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to cement ideas, we can also split out retweets from tweets. So if a tweet was a reply or an original tweet, we include it in the `tweet_count` total below and otherwise if it is a retweet we count it in the `retweet_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2 = read_csv(\"https://github.com/computationaljournalism/columbia2020/raw/master/data/learn_counts2.csv\")\n",
    "counts2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Slightly more advanced plotting and DataFrame concepts** \n",
    "\n",
    "Ideally we'd like to make a single plot with two lines - one for the retweets and one for the tweets. Do they have a similar pattern? For this, we are in need of sligly more from plotly and not just the `express`. Here we create two `Scatter()` plots and add them to a `Figure()`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.graph_objects import Scatter, Figure\n",
    "\n",
    "# Make a plotly figure\n",
    "fig = Figure()\n",
    "\n",
    "# Add a \"trace\" to the plot corresponding to a line we'd like to plot - \"time\" on the \n",
    "# x-axis and \"tweet_count\" on the y-axis\n",
    "\n",
    "fig.add_trace(Scatter(x=counts2[\"time\"], y=counts2[\"tweet_count\"], name=\"tweet count\"))\n",
    "\n",
    "# And add a \"trace\" to the plot corresponding to a line we'd like to plot - \"time\" on the \n",
    "# x-axis and now \"tweet_recount\" on the y-axis\n",
    "\n",
    "fig.add_trace(Scatter(x=counts2[\"time\"], y=counts2[\"retweet_count\"],name=\"retweet count\"))\n",
    "\n",
    "# Display the figure\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that something sneaky has happened in the `Scatter()` calls. We have \"subset\" the DataFrame to pull out the columns corresponding to the x- and y-axes. This subsetting, **like all subsetting we've seen so far**,  happens with square braces. `counts2[\"time\"]` pulls out just the column of data named `time` and uses it for the data on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put code here to pull out the column of \"tweet_count\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we are here, if we want to extract more than one column from a DataFrame, we would not specify just a column name, but provide a list of column names. Below we have a list of two columns `[\"time\",\"tweet_count\"]` and then we put that into the square brackets to subset `counts2[]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2[ [\"time\",\"tweet_count\"] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of several advantages of using a DataFrame is that we can operate on whole columns at once simply. Suppose we want to add the number of tweets (`tweet_count`) and retweets (`retweet_count`) to get a sense of the overall tweeting activity around the \"Learn to Code\" meme. We can do that easily as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2[\"tweet_count\"]+counts2[\"retweet_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also store this as a new column in the DataFrame. This is so slick! We'll call the new column `activity`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2[\"activity\"] = counts2[\"tweet_count\"]+counts2[\"retweet_count\"]\n",
    "\n",
    "# look at the \"head\" or the first five rows of the updated \"counts2\" DataFrame\n",
    "counts2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila! We will see the great things from DataFrames over time. As an aside, notice that while a DataFrame is like a spreadsheet, all of the updates you might make are recorded in code - code you can share with people who can check your work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to \"counts2\" called \"proportion\" that is the percentage \n",
    "# of tweeting activity that is original tweets, not retweets\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. Tables again**\n",
    "\n",
    "We created our first DataFrame from a list of dictionaries. Each row was an element of the list and the dictionary let us name the attributes we had about each item represented by a row. There is a more compact way of accomplishing the same thing if we know that each entry in our list holds data in the same order - day then count. Like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [\n",
    "    [\"2019-01-30\",2767],\n",
    "    [\"2019-01-29\",20250],\n",
    "    [\"2019-01-28\",37595],\n",
    "    [\"2019-01-27\",9209],\n",
    "    [\"2019-01-26\",7448],\n",
    "    [\"2019-01-25\",8412],\n",
    "    [\"2019-01-24\",6279],\n",
    "    [\"2019-01-23\",970],\n",
    "    [\"2019-01-22\",679],\n",
    "    [\"2019-01-21\",540],\n",
    "    [\"2019-01-20\",474]\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we have a list of lists! OK this is now very much in the weeds, but we turn this structure into a DataFrame as we had before, this time we have to provide a list with elements that name the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = DataFrame(times,columns=[\"day\",\"count\"])\n",
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of a DataFrame as a grid where we know columns all have the same kind of data and each row refers to a different unit of observation. This format is central to most machine learning exercises and statistical analysis.\n",
    "\n",
    "<img src=https://raw.githubusercontent.com/computationaljournalism/columbia2020/master/images/t.jpeg width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Some exercises**\n",
    "\n",
    "<img src=\"https://cdn.theatlantic.com/assets/media/img/mt/2020/01/GettyImages_632692308_edit/lead_720_405.jpg?mod=1580148502\" width=500>\n",
    "\n",
    "The Senate's impeachment trial has dominated the news over the last few days. As The Atlantic has reported [\"C-SPAN Is So Hot Right Now\"](https://www.theatlantic.com/politics/archive/2020/01/c-span-impeachment-trump/605602/). In their Twitter feed, they've also taken a dive into data journalism. Here are some facts about the different teams speaking during the proceedings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">INFOGRAPHIC: Amount of time White House Counsels spoke during Senate Impeachment Trial. <a href=\"https://t.co/ch4PgQU1Tq\">pic.twitter.com/ch4PgQU1Tq</a></p>&mdash; CSPAN (@cspan) <a href=\"https://twitter.com/cspan/status/1222273532039778306?ref_src=twsrc%5Etfw\">January 28, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">INFOGRAPHIC: Amount of time White House Counsels spoke during Senate Impeachment Trial. <a href=\"https://t.co/ch4PgQU1Tq\">pic.twitter.com/ch4PgQU1Tq</a></p>&mdash; CSPAN (@cspan) <a href=\"https://twitter.com/cspan/status/1222273532039778306?ref_src=twsrc%5Etfw\">January 28, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and here is a summary of the trial questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Senate Impeachment Trial Questions By the Numbers:<br><br>- Senators asked 180 Questions<br>- 76 were directed to White House Counsel<br>- 73 were directed to the House Managers<br>- 31 were directed to both <br><br>Overall:<br>- Philbin answered 66<br>- Schiff answered 53<br>- There were 211 total responses <a href=\"https://t.co/FNkhfBMmWE\">pic.twitter.com/FNkhfBMmWE</a></p>&mdash; CSPAN (@cspan) <a href=\"https://twitter.com/cspan/status/1223396021956423681?ref_src=twsrc%5Etfw\">February 1, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">Senate Impeachment Trial Questions By the Numbers:<br><br>- Senators asked 180 Questions<br>- 76 were directed to White House Counsel<br>- 73 were directed to the House Managers<br>- 31 were directed to both <br><br>Overall:<br>- Philbin answered 66<br>- Schiff answered 53<br>- There were 211 total responses <a href=\"https://t.co/FNkhfBMmWE\">pic.twitter.com/FNkhfBMmWE</a></p>&mdash; CSPAN (@cspan) <a href=\"https://twitter.com/cspan/status/1223396021956423681?ref_src=twsrc%5Etfw\">February 1, 2020</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Take some aspect of the Senate's impeachment trial and represent it as a DataFrame. You can make it by hand, either as a list of lists or a list of dictionaries. Perhaps you record the time used by each speaker, with whether they are a Manager or a member of the defense. Or you could categorize questions submitted, by whom and maybe the text of the question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**9. Booleans**\n",
    "\n",
    "Returning to the built-in data types, there's one more important one. It has only two values - `True` and `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  data type above is called *Boolean.* It represents just two states — true and false. Boolean data are generated by typing the special sequences of characters `True` or `False` (without quotations because they are not strings). \n",
    "\n",
    "You will primarily encounter Booleans as the output of some **logical expression.** Here are some examples of expressions that return Boolean (True/False) data. Try the expressions below — each asks whether a relationship holds or not, is true or false.\n",
    "\n",
    "*Riddle me this: Is 3 bigger than 5?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 > 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Riddle me this: Is 10 smaller than 100?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10.0 < 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Riddle me this: Is the letter 'e' in 'Adam Schiff'?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"e\" in \"Adam Schiff\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Riddle me this: Is the letter 'a' in 'Donald Trump'?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"a\" in \"Donald Trump\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first two logical expressions in the code above make **comparisons** while the second two test for **membership**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called \"tweet\", a string that holds the text from\n",
    "# one of Trump's recent tweets. Write an expression to see if it refers to \"Pelosi\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable called \"followers\", an integer holding the number of followers \n",
    "# a user has on Twitter. Give it the value for the `@nytimes`. Write an expression\n",
    "# to test if the number of followers for the account is larger than 1 million. Try this\n",
    "# with follower counts for 3 other users.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Boolean type will be important when we start to write code that \"branches\" its behavior depending on whether some condition is true or false — we might want to take one action if something is true, but another action if that thing is false. For example, we might want to analyze only the tweets coming from the President's mobile device and would use a Boolean to separate out those cases. Or we might just want tweets that have been retweeted a large number of times.\n",
    "\n",
    "With this in mind, sometimes, you will want to take action based on a combination of conditions. For this, we use \"and\", \"or\" and \"not\" to build more complicated expressions. \n",
    "\n",
    "*A series of logical expressions joined with 'and', for example, is True only if all the expressions are True.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"a\" in \"Adam Schiff\" and 3 < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"z\" in \"Adam Schiff\" and 3 < 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A series of conditions joined with 'or' is True if at least one expression is True.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"u\" in \"Adam Schiff\" or 3 < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3>10 or 5>100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*And you can flip from True to False (and vice versa) using the world 'not'. This is also called \"negation\".*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not \"u\" in \"Donald Trump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3<10 and not 5>100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*As with simple algebraic expressions like (1+3)\\*5, we can use parentheses to make sure our expressions are evaluated in the right order.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6 > 5 or (2 > 5 and \"u\" in \"Trump\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you see why this evaluated to True. Finally, keep in mind, all of these expressions return a Boolean object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(3<10 and not 5>100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technically, all of these symbols (\">\", \"<\", \"in\", \"and\", \"or\" and \"not\") are examples of **operators** in Python. The simplest kind of operators are arithmetic. They probably would have been a better place to start (as we did in the last class) — they underscore the idea that Python acts like a big calculator. Here \"+\" and \"\\*\" and \"/\" are called **arithmetic operators.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "100*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3*(100+2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, Python 'overloads' its operators so they can behave differently depending on what arguments you pass them. And the results can be surprising. Take arithmetic operations on strings, for example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"#LearnToCode\"+\" tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5*\"Tweets \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"a\",\"b\",\"c\"]+[\"d\",\"e\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"a\",\"b\"]*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read about the various operators in Python [here](http://www.tutorialspoint.com/python/python_basic_operators.htm). It's a clean summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Applying booleans**\n",
    "\n",
    "Using a boolean on a single value is useful, but often booleans will come in handy when selecting cases for study from a DataFrame. Perhaps we want to look only at the data from the defense team in the Senate impeachment trial, or perhaps we want tweets during a particular time period. \n",
    "\n",
    "To test this out, we have created a CSV file where each row is a tweet having to do with the \"Learn to Code\" meme. This file is big so you have to download it. I put it up [on Dropbox](https://www.dropbox.com/s/ene3qllvkwzolof/learn_tweets.csv?dl=0) — download it and put it in the same folder as your notebook. Then you should be able to read it in using the commands below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv, set_option\n",
    "\n",
    "# set the maximum number of characters in any cell\n",
    "set_option(\"display.max_colwidth\", 280)\n",
    "\n",
    "tweets = read_csv(\"learn_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to prepare you with some tools to help you extract the content from this table and ask about tweeting activity. Who was the most tweeted in this little episode? Who was the most tweeted *at*? For example, we can figure out who tweeted the most on this topic with a method of the column of a DataFrame called `value_counts()`. \n",
    "\n",
    "It takes the data in the column `screen_name` and then tabulates how many times each person tweeted on the \"Learning to code\" meme (or at very least used one of the hashtags we identified). That tabulation can then be printed out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['screen_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see how we can subset not just columns of a DataFrame as we did before, but also rows. For example, we might pull out the rows (tweets) associated with the top tweeter on the \"Learn to Code\" meme. Recall the symbol `==` is a called an operator, a logical operator, that returns another kind of built-in variable, \"a boolean\" - which takes on just the values of `True` and `False`.\n",
    "\n",
    "Through the \"subsetting\" below, we keep just the rows associated with `True` (that the `screen_name` of the tweeter is `ham_gretsky`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets[\"screen_name\"]==\"ham_gretsky\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack what we've done here. First, `tweets[\"screen_name\"]` extracts the column of screen names from our DataFrame. Remember? Try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"screen_name\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, to each element in the column, we apply the logical operator `==` to see if each equals `ham_gretsky`. What you should get back is a column of `True` and `False` booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[\"screen_name\"] == \"ham_gretsky\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use  square brackets to subset `tweets[]` and keep only the rows that are boolean expression has evaluated as `True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "popular = tweets[tweets[\"screen_name\"] == \"ham_gretsky\"]\n",
    "\n",
    "# The above creates a smaller DataFrame - let's look at its head\n",
    "popular.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we create our subset of the original DataFrame. It consists of 236 tweets and above we displayed the first five (the `head()`). \n",
    "\n",
    "So we've seen two kinds of subsetting with `tweets[]`. If we put in the square braces names of columns, we reduce the DataFrame and keep only the columns we specify. If, instead, we provide a collection of boolean `True` and `False` values (one for each row in the DataFrame), we keep only the rows that are `True`. \n",
    "\n",
    "As you can see from the reduced DataFrame above, the most prolific tweeter in our data set are using the meme in a \"sincere\" way, commenting on programming and looking for peopel to write tutorials.\n",
    "\n",
    "Can you see the potential here? Logical operators let you subset rows where the number of followers is larger than 5,000 or the total number of tweets by a person is larger than 100. Much of our data analysis will involve simple steps like these.\n",
    "\n",
    "**D. In the cell below, look at just the tweets from BeastOfWood. Is this a coder or someone participating in the meme aimed at journalists?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Appendix. One last example (not mandatory, but good practice!)**\n",
    "\n",
    "In class last time, Sara reminded us that on January 7 of last year, Axios published a \"scoop\" describing the President's daily schedule based on \"his private schedule shown to Axios.\"\n",
    "\n",
    ">[Scoop: Trump's secret, shrinking schedule](https://www.axios.com/scoop-trumps-secret-shrinking-schedule-1515364904-ab76374a-6252-4570-a804-942b3f851840.html)<br>\n",
    "President Trump is starting his official day much later than he did in the early days of his presidency, often around 11am, and holding far fewer meetings, according to copies of his private schedule shown to Axios. This is largely to meet Trump’s demands for more “Executive Time,” which almost always means TV and Twitter time alone in the residence, officials tell us.\n",
    "\n",
    "Axios released [the President's complete schedule in PDF format](https://www.documentcloud.org/documents/5720284-Axios-President-Donald-Trump-Private-Schedules.html), prompting a new round of coverage in [The Guardian](https://www.theguardian.com/us-news/2019/feb/03/trump-executive-time-axios), [Vox](https://www.vox.com/policy-and-politics/2019/2/4/18210345/trump-executive-time-axios-private-schedule-leak) and elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A White House aide is weaponizing his schedules, which says a lot about how people in the White House feel about the man they work for <a href=\"https://t.co/76K7XCzwPD\">https://t.co/76K7XCzwPD</a></p>&mdash; Maggie Haberman (@maggieNYT) <a href=\"https://twitter.com/maggieNYT/status/1092194637958258690?ref_src=twsrc%5Etfw\">February 3, 2019</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">A White House aide is weaponizing his schedules, which says a lot about how people in the White House feel about the man they work for <a href=\"https://t.co/76K7XCzwPD\">https://t.co/76K7XCzwPD</a></p>&mdash; Maggie Haberman (@maggieNYT) <a href=\"https://twitter.com/maggieNYT/status/1092194637958258690?ref_src=twsrc%5Etfw\">February 3, 2019</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Axios' PDF, each schedule entry is represented by a few lines of text that we might want to perform analysis on. **Let's start by reading the text and describing what questions you would like to answer about this document (and, in turn, how the President spends his time), and what data we might want to extract from the PDF for each event in his diary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Axios also made the data available in a CSV (comma-separated values) format, meaning a table or spreadsheet. You can see [the table here](https://docs.google.com/spreadsheets/d/1oITCuVsYdhNXtY7GElLelsrbjRRIPJ1ce-_v-8J1X_A/edit#gid=0). Have a look. Each row represents one of Trump's diary entries and each column represents a certain \"measurement\" or observation about each event. \n",
    "\n",
    "Did they reduce each verbal description of the events in the President's schedule into table entries the way you'd hoped? Anything missing?\n",
    "\n",
    "Download the table as \"CSV\" and save it in the same folder as your notebook.\n",
    "\n",
    "**Relation to built-in types.** The table we have downloaded is in a special form. Each row represents a unit of observation (in this case, a diary entry, but last time each row was a tweet contributing to the \"learn to code\" meme) and each column is a kind of measurement taken on the different object under study. So for the diary entries our \"measurements\" have to do with start time and end time and duration of meetings, along with location and attendees. Neither dictionaries nor lists completely capture this tabular structure. We have seen attempts at it. \n",
    "\n",
    "1. Dictionary of lists. Here's one way to structure the first five rows of the table. Each column is an element of a dictionary, where the `keys` are the column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"week\":[1,1,1,1,1],\n",
    "  \"date\":[\"2018-11-07\",\"2018-11-07\",\"2018-11-07\",\"2018-11-07\",\"2018-11-07\"],\n",
    "  \"time_start\":[\"08:00\",\"11:00\",\"11:30\",\"12:30\",\"13:30\"],\n",
    "  \"time_end\":[\"11:00\",\"11:30\",\"12:30\",\"13:30\",\"17:00\"],\n",
    "  \"duration\":[3,0.5,1,1,3.5],\n",
    "  \"listed_title\":[\"Executive time\",\"Meeting with the chief of staff\",\"Executive time\",\"Lunch\",\"Executive time\"],\n",
    "  \"top_category\":[\"executive_time\",\"meeting\",\"executive_time\",\"lunch\",\"executive_time\"],\n",
    "  \"listed_location\":[\"Oval office\",\"Oval office\",\"Oval office\",\"Private dining room\",\"Oval office\"],\n",
    "  \"listed_project_officer\":[0,0,0,0,0],\n",
    "  \"detail_category\":[\"executive_time\",\"cos_meeting\",\"executive_time\",\"solo_lunch\",\"executive_time\"]\n",
    "}\n",
    "\n",
    "# Write some code to extract the duration of the third meeting of the day\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Lists of dictionaries. The rows are now organized as dictionaries and each row is an element in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"08:00\",\"time_end\":\"11:00\",\"duration\":3,\"listed_title\":\"Executive time\",\"top_category\":\"executive_time\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"executive_time\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"11:00\",\"time_end\":\"11:30\",\"duration\":0.5,\"listed_title\":\"Meeting with the chief of staff\",\"top_category\":\"meeting\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"cos_meeting\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"11:30\",\"time_end\":\"12:30\",\"duration\":1,\"listed_title\":\"Executive time\",\"top_category\":\"executive_time\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"executive_time\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"12:30\",\"time_end\":\"13:30\",\"duration\":1,\"listed_title\":\"Lunch\",\"top_category\":\"lunch\",\"listed_location\":\"Private dining room\",\"listed_project_officer\":null,\"detail_category\":\"solo_lunch\"},\n",
    "    {\"week\":1,\"date\":\"2018-11-07\",\"time_start\":\"13:30\",\"time_end\":\"17:00\",\"duration\":3.5,\"listed_title\":\"Executive time\",\"top_category\":\"executive_time\",\"listed_location\":\"Oval office\",\"listed_project_officer\":null,\"detail_category\":\"executive_time\"}\n",
    "]\n",
    "\n",
    "# Write code to extract the start and end times of the second event of the day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. A list of lists. In Mr. Data Converter this is called JSON - Row Arrays. This one has the slight disadvantge in that the column names are lost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "  [1,\"2018-11-07\",\"08:00\",\"11:00\",3,\"Executive time\",\"executive_time\",\"Oval office\",0,\"executive_time\"],\n",
    "  [1,\"2018-11-07\",\"11:00\",\"11:30\",0.5,\"Meeting with the chief of staff\",\"meeting\",\"Oval office\",0,\"cos_meeting\"],\n",
    "  [1,\"2018-11-07\",\"11:30\",\"12:30\",1,\"Executive time\",\"executive_time\",\"Oval office\",0,\"executive_time\"],\n",
    "  [1,\"2018-11-07\",\"12:30\",\"13:30\",1,\"Lunch\",\"lunch\",\"Private dining room\",0,\"solo_lunch\"],\n",
    "  [1,\"2018-11-07\",\"13:30\",\"17:00\",3.5,\"Executive time\",\"executive_time\",\"Oval office\",0,\"executive_time\"]\n",
    "]\n",
    "\n",
    "# Write some code to extract the 'listed_title' of the second event.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now read the CSV into Pandas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "diary = read_csv(\"Axios _ President Donald Trump Private Schedules, Nov. 7, 2018 to Feb. 2, 2019 - data.csv\")\n",
    "diary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see by scrolling that we list out the first and last 30 rows. If you scroll all the way down to the bottom, you'll see there are 577 rows in total. But you can get at this directly -- a DataFrame object has an attribute that stores its dimensions (number of rows and columns). It's called `shape`. \n",
    "\n",
    "Again you access attributes with the \"dot\" notation, and because we are looking up information and not computing something (like making strings lowercase, say), we don't need parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So We have 577 meetings (rows in the table) and 11 variables recorded for each. We can have a look at the \"top\" and \"bottom\" of the data set. These are printed with `head()` and `tail()`methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `head()` and `tail()` methods of a DataFrame gives you five time periods from the start and end of the data (and you can give an argument to see more). It's important to look at the top and bottom of the file to check that everything looks consistent (column entries seem to mean what they should) and see how the data might be organized.\n",
    "\n",
    "Some of the primary operations we perform on tables are simple ordering of rows and \"subsetting\" either rows or columns -- identifying data that's worth a second look. Here we use the method `.sort_valeus()` to sort the rows of the data frame according to some variable. Here we take `duration`, from smallest to largest. (How would you sort in descending order of duration? Google!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diary.sort_values('duration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can involve more than one column in the sort. Just include their names in a list. The method `.sort_values()` takes either a column name (string) or a list of names (list of strings). If it's a list it orders the rows by the first column name first, then by the values under the second, third and so on column names in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary.sort_values(['time_start','duration'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to sorting, we might want to focus our attention only on certain columns. We can select columns from a DataFrame using the same convention as with sorting. We provide either a single column name or a list of column names that we'd like to pull out from the data frame. \n",
    "\n",
    "The syntax is meant to look like that of a dictionary -- You give names, contained in square braces. So here we are keeping the `listed_title` and then the `listed_title` along with the duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"listed_title\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[ [\"listed_title\",\"duration\"] ].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I added an extra space to separate the square braces in `diary[ ]` from the square braces defining the list of column names we wanted `[\"listed_title\",\"duration\"]`. You don't need the space and you probably won't include it, but for the first time seeing it, it might help.\n",
    "\n",
    "Now, given the data from a single column, we might want to create a table of values. For example, what is the breakdown of the `listed_title` column? The method `.value_counts()` will take a column and tabulate the number of each unique entry. Here we see `Executive time` has the highest count by a long shot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary['listed_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code to tabulate the number of meetings per day\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pushing a little farter, we can pull out all the `listed_title` data into a single column using subsetting (with square braces and the column name)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"listed_title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and we can ask if they equal `Executive time` or not. This uses our comparison operator `==` but with a Data Frame, it can run down the whole column at once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"listed_title\"] == \"Executive time\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `True` and `False` data to subset rows of the table -- here we keep just the rows where the title is \"`Executive time`\". **Keep in mind that our subsetting expressions now work in two ways.** \n",
    "\n",
    "Using `diary[ ]`, we can select columns by giving a name or list of names. With the next expression we see that if we provide a column of `True` and `False` values, the subsetting will keep just the portion of the table with `True`, or in this case, where we have `Executive time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[ diary[\"listed_title\"] == \"Executive time\" ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now the simplest thing to do is just sum up the total duration spent in executive time. First, let's sum up the durations for the entire data frame... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diary[\"duration\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and then subset the data frame to just the executive time entries and form a sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_diary = diary[ diary[\"listed_title\"] == \"Executive time\" ]\n",
    "exec_diary[\"duration\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could use `sum()` as we did with `followers` in our drill, but the nice thing about the method associated with the data frame column is that it removes the missing values when it forms the sum. That makes life easier. There are a few entries that have missing durations -- listed as NaN.\n",
    "\n",
    "And the headline for so many stories comes from this computation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "297/503"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
